<!DOCTYPE html>
<html data-n-head="" data-n-head-ssr>
  <head>
    <meta data-n-head="true" charset="utf-8"><meta data-n-head="true" content="width=device-width,initial-scale=1" name="viewport"><meta data-n-head="true" content="Joy Programming Language" name="description" data-hid="description"><title data-n-head="true">Joy language</title><link href="https://fonts.googleapis.com/css?family=Fira+Sans:200,500|Roboto:400|Roboto+Mono:400" rel="stylesheet" data-n-head="true"><link href="/favicon.ico" rel="icon" data-n-head="true" type="image/x-icon"><link href="/favicon.ico?" rel="shortcut icon" data-n-head="true" type="image/x-icon"><link href="/_nuxt/manifest.10669f42b2e188f55eb1.js" rel="preload" as="script"><link href="/_nuxt/vendor.230cb916d1973aa790f3.js" rel="preload" as="script"><link href="/_nuxt/app.0a856c7cf6fb3e349fa2.js" rel="preload" as="script"><link href="/_nuxt/layouts/default.29c0e08e13310e3682fc.js" rel="preload" as="script"><link href="/_nuxt/pages/papers-on-joy.cad646018fcc11e7f563.js" rel="preload" as="script"><link href="/_nuxt/pages/papers-on-joy/recursion-theory-and-joy.7d268252a6e6c71fa9f2.js" rel="preload" as="script"><link href="/_nuxt/pages/papers-on-joy/survey-of-reproducing-programs.ed8409adcfb2bdec6eeb.js" rel="prefetch"><link href="/_nuxt/pages/libraries-and-c-sources.d2ffa370ff989df9d359.js" rel="prefetch"><link href="/_nuxt/pages/index.73b5e04f9a3fcda5b5fe.js" rel="prefetch"><link href="/_nuxt/pages/about.a3431c5910b96e7d0298.js" rel="prefetch"><link href="/_nuxt/pages/papers-on-joy/the-algebra-of-joy.7f385b55e84045676f24.js" rel="prefetch"><link href="/_nuxt/pages/papers-on-joy/the-annoying-quadratic-formula.a3d9ef30d4f74df89dfd.js" rel="prefetch"><link href="/_nuxt/pages/papers-on-joy/church-arithmetic-and-church-logic-with-brent-kirby.e11588a1a251690d41af.js" rel="prefetch"><link href="/_nuxt/pages/rationale-for-joy.3e067852511f512169f0.js" rel="prefetch"><link href="/_nuxt/pages/papers-on-joy/tutorial-on-joy.9a4df70c3d63708c2b23.js" rel="prefetch"><link href="/_nuxt/pages/overview-of-joy.8733ad0cbce5d065d604.js" rel="prefetch"><link href="/_nuxt/pages/c-sources/miscellaneous-miniature-implementations-of-joy.417498df53623dd27f3a.js" rel="prefetch"><link href="/_nuxt/pages/papers-on-joy/fast-small-truth-tables.9b1b75741215fa7afac3.js" rel="prefetch"><link href="/_nuxt/pages/papers-on-joy/programming-in-joy.d4bc3bc57b9855085dc1.js" rel="prefetch"><link href="/_nuxt/pages/papers-on-joy/design-of-matrix-multiplication-programs.8e00ebe2e6e430523681.js" rel="prefetch"><link href="/_nuxt/pages/papers-on-joy/imperative-thinking-for-joy-programs.223ec58c271bc7112421.js" rel="prefetch"><link href="/_nuxt/pages/papers-on-joy/design-of-a-joy-interpreter-written-in-joy.eaa748fa0ea2130e1164.js" rel="prefetch"><link href="/_nuxt/pages/papers-on-joy/joy-compared-with-other-functional-languages.e9b1e34a3b81758a64f2.js" rel="prefetch"><link href="/_nuxt/pages/papers-on-joy/nested-recursion-and-a-new-recursion-combinator.d40eac9bf6ad0e5cac92.js" rel="prefetch"><link href="/_nuxt/pages/faq.9ffdbd52d27b2df75f94.js" rel="prefetch"><link href="/_nuxt/pages/papers-on-joy/mathematical-foundations-of-joy.4f0b584e560cf803bb24.js" rel="prefetch"><link href="/_nuxt/pages/papers-on-joy/floy-a-flat-concatenative-subset-of-joy.9162d7b51e29e1b5b1b9.js" rel="prefetch"><link href="/_nuxt/pages/papers-on-joy/html-manual.e3473b0453170639a088.js" rel="prefetch"><link href="/_nuxt/pages/faq-part-2.9630745e3aaebc47633f.js" rel="prefetch"><link href="/_nuxt/pages/papers-on-joy/lazy-lists-as-reproducing-programs.9516d2d5134cfed90ce3.js" rel="prefetch"><link href="/_nuxt/pages/papers-on-joy/the-current-implementation.e033c23017443bc35c24.js" rel="prefetch"><link href="/_nuxt/pages/papers-on-joy/a-rewriting-system-for-joy.4157d6f1ef190fb675ea.js" rel="prefetch"><link href="/_nuxt/pages/papers-on-joy/atomic-programs-of-joy.f2cb1414ae2b6ed9401e.js" rel="prefetch"><link href="/_nuxt/pages/c-sources/prospectus-for-john-cowans-joy1.cb4661329c1ed2df6752.js" rel="prefetch"><style data-vue-ssr-id="d505b096:0">html{font-family:Roboto,Arial,sans-serif;margin:0;font-weight:400;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;-webkit-box-sizing:border-box;box-sizing:border-box}body{margin:0;height:100%}:after,:before,:not(pre){-webkit-box-sizing:border-box;box-sizing:border-box;margin:0}.wrapper{min-height:calc(100vh - 102px)}a{color:#3273dc;text-decoration:none}a:hover{text-decoration:underline}</style><style data-vue-ssr-id="6cc65792:0">nav[data-v-251e63b6]{background-color:#000}ul[data-v-251e63b6]{list-style-type:none;padding:0;margin:0}li[data-v-251e63b6]{-webkit-transition:all .2s ease-out;transition:all .2s ease-out;display:inline-block;padding:0;cursor:pointer}li[data-v-251e63b6]:hover{-webkit-transform:scale(1.04);transform:scale(1.04);background-color:#fff;color:#000}li a[data-v-251e63b6]{display:block;padding:15px 25px;text-decoration:none;color:#fff;text-align:center}li:hover a[data-v-251e63b6]{color:#000}.nuxt-link-exact-active[data-v-251e63b6]{text-decoration:overline}</style><style data-vue-ssr-id="23d2604d:0">h1[data-v-7e83a563]{font-size:26px}.lists[data-v-7e83a563]{margin-top:37px;padding-left:12vw;padding-right:12vw}.top-list-item[data-v-7e83a563]{margin-top:11px}li[data-v-7e83a563]{line-height:39px}.no-style-litem[data-v-7e83a563]{list-style-type:none}ul[data-v-7e83a563]{list-style-type:circle}h6[data-v-7e83a563]{font-size:17px}p[data-v-7e83a563]{margin-top:8px;line-height:24px;font-size:16px}</style><style data-vue-ssr-id="1e1a9c16:0">p[data-v-5c36311d]{margin-top:16px;margin-bottom:16px}hr[data-v-5c36311d]{margin-bottom:16px}pre[data-v-5c36311d]{margin-bottom:auto}code[data-v-5c36311d],kbd[data-v-5c36311d],pre[data-v-5c36311d]{font-family:Roboto Mono,monospace}</style><style data-vue-ssr-id="ca9343dc:0">footer[data-v-c785faa8]{padding:11px 20px 0;height:52px}p[data-v-c785faa8]{-webkit-transition:all .1s ease-in;transition:all .1s ease-in;font-size:15px;float:right;margin:0 16px}a[data-v-c785faa8]{color:#000;text-decoration:none}p[data-v-c785faa8]:hover{-webkit-transform:scale(.94);transform:scale(.94);color:#000;-webkit-text-decoration:#3273dc overline;text-decoration:#3273dc overline}</style>
  </head>
  <body data-n-head="">
    <div id="__nuxt" data-server-rendered="true"><div id="__layout"><div class="container" lang="en"><nav data-v-251e63b6 role="navigation"><ul data-v-251e63b6><li data-v-251e63b6><a href="/" data-v-251e63b6 class="nuxt-link-active">Home</a><li data-v-251e63b6><a href="/papers-on-joy" data-v-251e63b6 class="nuxt-link-active">Papers</a><li data-v-251e63b6><a href="/libraries-and-c-sources" data-v-251e63b6>Libraries/C sources</a><li data-v-251e63b6><a href="/about" data-v-251e63b6>About</a></ul></nav><main class="lists" data-v-7e83a563><div data-v-7e83a563><article data-v-5c36311d data-v-7e83a563 data-v-7e83a563><h1 data-v-5c36311d>Recursion Theory and Joy</h1><i data-v-5c36311d> by Manfred von Thun </i><p data-v-5c36311d><em data-v-5c36311d>Abstract:</em> Joy is a functional programming language which is not based
    on the application of functions to arguments but on the composition of functions.
    Many topics from the theory of computability are particularly easy to handle within
    Joy. They include the parameterisation theorem, the recursion theorem and Rice's
    theorem. Since programs are data, it is possible to define a Y-combinator for recursion
    and several variants. It follows that there are self-reproducing and self-describing
    programs in Joy. Practical programs can be written without recursive definitions
    by using several general purpose recursion combinators which are more intuitive
    and more efficient than the classical ones.
  <p data-v-5c36311d><em data-v-5c36311d>Keywords:</em> functional programming, functionals, computability, diagonalisation,
    program = data, diagonalisation, self-reproducing and self-describing programs,
    hierarchy of recursion combinators, elimination of recursive definitions.
  <hr data-v-5c36311d><h2 data-v-5c36311d>Introduction</h2>
  This paper describes some aspects of the language from the perspective of recursive
  function theory.
  <p data-v-5c36311d>
    A deep result in the theory of computability concerns the elimination of recursive
    definitions. To use the stock example, the
    <em data-v-5c36311d>factorial</em> function can be <em data-v-5c36311d> defined</em> recursively in Joy by
  <pre data-v-5c36311d>        factorial  ==
              [0 =] [pop 1] [dup 1 - factorial *] ifte
  </pre>
  The definition is then <em data-v-5c36311d> used</em> in programs like this:
  <pre data-v-5c36311d>        5
          factorial
  </pre>
  Because in Joy programs can be manipulated as data, the factorial function
  can also be computed recursively without a recursive definition, as follows:
  <pre data-v-5c36311d>        5
          [ [pop 0 =] [pop pop 1] [[dup 1 -] dip i *] ifte ]
          [dup cons] swap concat dup cons i
  </pre>
  The second line in this program does much the same as the body of the definition
  of factorial, but it is a quoted program. The third line first transforms this into
  another longer quoted program which performs "anonymous" recursion, and then the
  final <kbd data-v-5c36311d>i</kbd> combinator essentially dequotes this program causing its execution.
  <p data-v-5c36311d>
    The third line implements Joy's counterpart of the <em data-v-5c36311d>Y
    combinator</em> of the lambda calculus and of combinatory logic. Exactly the same
    line can be used to cause anonymous recursion of other functions which are normally
    defined recursively.
  <p data-v-5c36311d>
    Joy has other combinators which make recursive execution of programs more succinct.
    (Of course it is also possible in Joy to compute the factorial function more efficiently
    with iteration instead of recursion.)
  <p data-v-5c36311d>
    The remainder of this paper deals with various aspects of the theory of computability,
    in particular the theory of <em data-v-5c36311d>recursive
    function</em>s. The next section gives a recursive definition of a recursion combinator.
    Following that is a section dealing with various well known and elementary theorems
    from recursive function theory. The next section then proves a fixpoint theorem
    for Joy. The theorem implies the existence of self-reproducing programs, as shown
    in the following section. There is also some discussion of the effect of evaluation
    order on termination. The topic of the next section is Rice's theorem for Joy.
    Then there is a section describing further self-reproducing and self-describing
    programs. Another recursion combinator is constructed in the next section. The
    final section discusses the more practical recursion combinators of Joy. Previous
    knowledge of the field of recursion theory is not assumed.
  <h2 data-v-5c36311d>Recursion and its elimination</h2>
  The factorial function and the Fibonacci function are often used to illustrate two
  different recursion patterns, although both are most efficiently computed non-recursively.
  This section follows tradition by using these two functions. The ultimate aim is
  to show how
  <em data-v-5c36311d>recursive definition</em>s of functions can be eliminated to obtain a (closed)
  form of a program for <em data-v-5c36311d>recursive execution</em>.
  <p data-v-5c36311d>
    In conventional notation the <em data-v-5c36311d>factorial</em> function can be defined recursively
    like this:
  <pre data-v-5c36311d>    r-fac(n)  =  if n = 0 then 1 else n * r-fac(n - 1)
  </pre>
  It is obvious that in conventional notation the definitions need the formal
  parameter <code data-v-5c36311d>n</code>. Joy was designed to eliminate formal parameters in definitions,
  and the factorial function would be defined in Joy like this:
  <pre data-v-5c36311d>    r-fac1  ==  [0 =] [pop 1] [dup 1 - r-fac1 *] ifte
  </pre>
  The suffix <code data-v-5c36311d>1</code> serves to distinguish this definition from a later
  version. The RHS of the definition contains three quotations: an if-part, a then-part
  and an else-part. These serve as parameters to the <kbd data-v-5c36311d>ifte</kbd> combinator. The
  if-part tests for equality with <code data-v-5c36311d>0</code>, and if that is true then the then-part
  <kbd data-v-5c36311d>pop</kbd>s off the parameter and replaces it with the result
  <code data-v-5c36311d>1</code>. Otherwise the else-part is executed, which
  <kbd data-v-5c36311d>dup</kbd>licates the parameter, subtracts <code data-v-5c36311d>1</code> from the top copy,
  calls <code data-v-5c36311d>r-fac1</code> recursively on that and, when that call has returned with
  a value, multiplies that with the original. Using a more Joy-like idiom:
  <pre data-v-5c36311d>    r-fac1  ==  [null] [succ] [dup pred r-fac1 *] ifte
  </pre>
  This uses the <kbd data-v-5c36311d>null</kbd> predicate in the if-part, the
  <kbd data-v-5c36311d>succ</kbd>essor function in the then-part and the
  <kbd data-v-5c36311d>pred</kbd>ecessor operator in the else-part.
  <p data-v-5c36311d>
    In conventional notation the <em data-v-5c36311d>Fibonacci</em> function is defined recursively
    like this:
  <pre data-v-5c36311d>    r-fib(n)   =  if n &lt;= 1 then n else r-fib(n - 1) + r-fib(n - 2)
  </pre>
  A more or less literal translation into Joy is the following:
  <pre data-v-5c36311d>    r-fib1  ==  [small] [] [pred dup [r-fib1] dip pred r-fib1 +] ifte
  </pre>
  The if-part uses the <kbd data-v-5c36311d>small</kbd> predicate, which for numeric parameters
  yields <code data-v-5c36311d>true</code> for <code data-v-5c36311d>0</code> and for
  <code data-v-5c36311d>1</code>. The then-part is the empty quotation <code data-v-5c36311d>[]</code>, when executed
  it does nothing. In the else-part <code data-v-5c36311d>r-fib1</code> has to call itself twice, once
  each for the two parameters that have been prepared by <code data-v-5c36311d>dup</code>. The <kbd data-v-5c36311d>dip</kbd>combinator applies the quotation <code data-v-5c36311d>[r-fib1]</code> to the earlier version, and
  the later version, after <code data-v-5c36311d>pred</code> has done its job, is handled directly
  by <code data-v-5c36311d>r-fib1</code>. A cleaner version is
  <pre data-v-5c36311d>    r-fib2  ==  [small] [] [pred dup pred [r-fib2] app2 +] ifte
  </pre>
  The <kbd data-v-5c36311d>app2</kbd> combinator applies the quoted
  <code data-v-5c36311d>[r-fib2]</code> twice, to each of the two numbers on top of the stack.
  <p data-v-5c36311d>
    It will help if the minor differences between the definitions of the factorial function
    and the Fibonacci function are eliminated. In particular this concerns the patterns
    of the recursive calls. In the body of <code data-v-5c36311d>r-fac1</code> the direct recursive
    call has been replaced by its quotation and <kbd data-v-5c36311d>app1</kbd>, which applies the
    quotation just once, to the single number. So here are two other versions, they
    have aligned to make comparisons easier.
  <pre data-v-5c36311d>    r-fac2  ==  [ null] [succ] [     dup pred [r-fac2] app1 *] ifte
      r-fib2  ==  [small] [    ] [pred dup pred [r-fib2] app2 +] ifte
  </pre>
  The task of eliminating the recursion in the RHS of the definitions amounts
  to this: The occurrences of the quoted programs
  <code data-v-5c36311d>[r-fac2]</code> and <code data-v-5c36311d>[r-fib2]</code> have to be replaced by the quoted
  RHS. But this will introduce those same quotes again, and these have to be replaced
  by the RHS, and so on <em data-v-5c36311d> ad
  infinitum</em>. It seems impossible.
  <p data-v-5c36311d>
    One part of the solution is that the programs have to be given an extra parameter
    which is to be used when the else-part is executed. The extra parameter will have
    to contain whatever is necessary to enable the recursion inside the else-part.
    But this means that the extra parameter will be somewhat in the way. Consequently
    the if-part and the then-part need an extra <code data-v-5c36311d>pop</code> to remove the unneeded
    parameter. Furthermore, in the else-part any preparatory work before the actual
    recursion has to be done <em data-v-5c36311d> below</em> the extra parameter using <code data-v-5c36311d>dip</code>.
    The one or two recursions are then to be effected by <code data-v-5c36311d>app1</code> and <code data-v-5c36311d>app2</code>,
    respectively. The two programs now look like this:
  <pre data-v-5c36311d>?-fac:  [[pop  null] [pop succ] [[dup pred     ] dip app1 *] ifte] ?
  ?-fib:  [[pop small] [pop     ] [[pred dup pred] dip app2 +] ifte] ?
  </pre>
  To indicate that these are <em data-v-5c36311d> not</em> recursive definitions, they are not
  given as definitions at all. The <code data-v-5c36311d>?</code>-symbol is left unanalysed at this
  point, only this much can be said about it:
  <ol data-v-5c36311d><li data-v-5c36311d> it takes the entire quoted program as a parameter and then produces another quoted
      program with a special property.
    <li data-v-5c36311d> it then executes this resulting program.
    </ol>
  So the <code data-v-5c36311d>?</code>-symbol denotes a strange combinator.
  <p data-v-5c36311d>
    For comparison the three versions of the factorial program are listed here:
  <pre data-v-5c36311d>r-fac1 == [     null] [    succ] [ dup pred        r-fac1       *] ifte
  r-fac2 == [     null] [    succ] [ dup pred       [r-fac2] app1 *] ifte
  ?-fac:   [[pop  null] [pop succ] [[dup pred     ] dip      app1 *] ifte] ?
  </pre>
  And here are the three versions of the Fibonacci program:
  <pre data-v-5c36311d>r-fib1 == [    small] [        ] [ pred dup [r-fib1] dip r-fib1 +] ifte
  r-fib2 == [    small] [        ] [ pred dup pred  [r-fib2] app2 +] ifte
  ?-fib:   [[pop small] [pop     ] [[pred dup pred] dip      app2 +] ifte] ?
  </pre><p data-v-5c36311d>
    The recursion combinator must do this: At the point where
    <code data-v-5c36311d>?-fac</code> uses <code data-v-5c36311d>app1</code> and where <code data-v-5c36311d>?fib</code> uses <code data-v-5c36311d>app2</code>  they expect <code data-v-5c36311d>?-fac</code> and
    <code data-v-5c36311d>?fib</code> on top of the stack. That is why the if-parts and the then-parts
    each need an extra <code data-v-5c36311d>pop</code>, and why the else-part has to do its initial
    work from a <code data-v-5c36311d>dip</code>. It all means that a recursion combinator has to supply
    the RHS to itself as an extra parameter. In general, a recursion combinator expects
    a program <code data-v-5c36311d>[P]</code> and it executes it in a special way. It must call <code data-v-5c36311d>P</code>  but provide the extra parameter. This is the defining law for a recursion combinator
    <code data-v-5c36311d>?</code> :
  <pre data-v-5c36311d>        [P]  ?   ==   [[P] ?]  P
  </pre><p data-v-5c36311d>
    How can a recursion combinator be defined? This can be done recursively and non-recursively.
    Once the <code data-v-5c36311d>?</code> combinator is defined, it can be used to eliminate all
    other recursive definitions. If a recursion combinator is defined recursively,
    then this would be the only recursive definition that is needed. Here is a step-by-step
    development of such a definition. The development is a fairly typical example of
    how one can write Joy programs systematically. Start with the defining law:
  <pre data-v-5c36311d>        [P] ?
      ==  [[P] ?]  P
  </pre>
  In the second line <code data-v-5c36311d>P</code> occurred twice, in quoted and unquoted form.
  It will be simpler if it occurs in only one form, and that has to be the quoted form.
  So, using the <code data-v-5c36311d>i</code> combinator,
  <pre data-v-5c36311d>    ==  [[P] ?]  [P]  i
  </pre>
  The two quotations are not exactly the same, but they can be produced from
  two identical quotations:
  <pre data-v-5c36311d>    ==  [[P ?]  [[P] ?]  first  i
  </pre>
  Now the two identical quotations can be produced by the
  <code data-v-5c36311d>dup</code> operator:
  <pre data-v-5c36311d>    ==  [[P] ?]  dup  first  i
  </pre>
  All that is needed now is to extract <code data-v-5c36311d>[P]</code> to the left:
  <pre data-v-5c36311d>    ==  [P]  [?]  cons  dup  first  i
  </pre>
  In this construction each line was equivalent to its one or two neighbours.
  Hence the first and the last lines of this construction are equivalent:
  <pre data-v-5c36311d>        [P]  ?   ==   [P]  [?]  cons  dup  first  i
  </pre>
  Hence the following is a suitable recursive definition of a recursion combinator:
  <pre data-v-5c36311d>        ?   ==   [?]  cons  dup  first  i
  </pre><p data-v-5c36311d>
    It is useful to think of the RHS as being composed of two parts: the first is
  <pre data-v-5c36311d>        [?]  cons  dup  first
  </pre>
  and the second part is just <code data-v-5c36311d>i</code>. The first part is just a function
  which takes one quoted program as a parameter and produces two quoted programs as
  values:
  <pre data-v-5c36311d>        [P]  [?]  cons  dup  first
          [[P]  ?]  dup  first                    (by cons)
          [[P]  ?]  [[P]  ?]  first               (by dup)
          [[P]  ?]  [P]                           (by first)
  </pre>
  The second part of the definition is <code data-v-5c36311d>i</code>, which effectively dequotes
  the topmost <code data-v-5c36311d>[P]</code> and hence executes
  <code data-v-5c36311d>P</code>. So the next reduction step depend on what
  <code data-v-5c36311d>P</code> actually does.
  <p data-v-5c36311d>
    An alternative recursive definition may be constructed:
  <pre data-v-5c36311d>        [P]  ?
      ==  [[P] ?]  P
      ==  [[P] ?]  [P]  i
      ==  [P]  [?]  cons  [P]  i
      ==  [P]  [P]  [[?] cons]  dip  i
      ==  [P]  dup  [[?] cons]  dip  i
  </pre>
  The resulting alternative recursive definition is
  <pre data-v-5c36311d>        ?   ==   dup  [[?] cons]  dip  i
  </pre>
  It follows that the two RHSs of the two equivalent definitions are equal:
  <pre data-v-5c36311d>        [?]  cons  dup  first  i   ==   dup  [[?] cons]  dip  i
  </pre>
  (Note that cancellation of the trailing <code data-v-5c36311d>i</code> combinator on both
  sides is not valid in general, though it would be valid here.)
  <p data-v-5c36311d>
    We now have a recursive definition of recursion. Computationally this is quite adequate,
    the recursive definition of any one of the
    <code data-v-5c36311d>?</code> combinators really does make it possible to eliminate all other
    recursive definitions. Some of the following sections deal with the elimination
    of recursion even for the recursion combinators.
  <p data-v-5c36311d>
    The recursive definition of a recursion combinator can of course also be given in
    other languages. For an example in the lambda calculus see <a href="refs.html#{Henson87}" data-v-5c36311d>{Henson87}</a>.
    For an example in ML see <a href="refs.html#{Sokolowski91}" data-v-5c36311d>{Sokolowski91}</a>.
  <h2 data-v-5c36311d>Theorems in recursion theory</h2>
  The theory of <em data-v-5c36311d>computability</em> treats various formalisms which independently
  aim to capture the essence of computation. These formalisms include Turing machines,
  the lambda calculus, Markov algorithms, register machines, flow charts and any of
  the conventional programming languages. Each formalism deals with various specifications:
  for the Turing formalism the specifications are particular Turing machines, for the
  Markov formalism the specifications are particular Markov algorithms, for the programming
  languages they are particular programs, and so on. Some results in the theory concern
  connections between the formalisms, whereas others concern connections within the
  same formalism.
  <p data-v-5c36311d>
    The main results in the theory can be divided into two groups: those concerned with
    the relationships between two such formalisms and those concerned with just one.
  <p data-v-5c36311d>
    The principal results in the first group are that the formalisms are all equivalent,
    in this sense: Given any two formalisms, for any specification in the one formalism
    there is a specification in the other formalism such that the two specifications
    compute the same function. Proofs of such results are always constructive, by exhibiting
    an algorithm which converts any specification in the one formalism into a specification
    in the other.
  <p data-v-5c36311d>
    Results in the second group concern just one formalism and often take this form:
    For any specification S1 having a certain property there is another specification
    S2 such that the two specifications S1 and S2 are related in some special way.
    Proofs are again constructive, by exhibiting algorithms for converting S1 into
    S2.
  <p data-v-5c36311d>
    The algorithms of both groups can be expressed in any of the formalisms. The constructive
    proofs then look like this: There is a specification S (in formalism F) with the
    capacity of transforming any specification S1 (in formalism F1) into a specification
    S2 (in formalism F2, not necessarily different from F1) such that the two specification
    S1 and S2 are related in a special way. Since the formalisms are universal, the
    algorithms can be written in the formalism itself, as another specification S.
    The results then take this form: There is a specification S such that for every
    specification S1 the result of applying S to S1 yields the required S2.
  <p data-v-5c36311d>
    Historically the theory of computability has been mainly couched in terms of <em data-v-5c36311d>recursive function</em>s,
    a collection of functions built from a small base by means of a small number of
    constructors. These functions take natural numbers as arguments and give natural
    numbers as values. By means of a theoretically elegant (but computationally unfeasible)
    mapping called Gödel numbering, linguistic entities such as expressions can be
    assigned a unique number. In this way the functions can be made to "talk about
    themselves". Any syntactic operation on linguistic entities has a counterpart purely
    arithmetical operation on natural numbers which are the Gödel numbers of these
    entities. The theorems are basic to any proper understanding of the the foundations
    of computer science. But the proofs, when not hand-waiving by appeals to Church's
    thesis, tend to be forbidding.
  <p data-v-5c36311d>
    The ease of writing S depends crucially on how well the formalism can handle its
    own specifications. Often it is necessary to use encodings of S1 and S2 into a
    form which the formalism can handle. In the worst case the encodings are truly
    ghastly. In the best case the formalism can handle its own specifications very
    naturally. This is sometimes expressed by the slogan <em data-v-5c36311d>program = data</em>.
    Most formalisms fare badly on this, including most programming languages.
  <p data-v-5c36311d>
    Some languages can treat their own programs as data; they are Lisp, Snobol, Prolog
    and their descendants, some macro generators and the command languages based on
    them. Joy does it at least as well. In these languages programs can operate on
    other programs or on other data to produce other programs which may then be executed.
    Because of this, arithmetisation is not necessary, functions can take programs
    rather than Gödel numbers of programs as arguments, and metatheoretic proof become
    much easier. <a href="refs.html#{Phillips92}" data-v-5c36311d>{Phillips92}</a> writes
  <blockquote data-v-5c36311d>
    One might wonder how differently recursion theory might be viewed if it had arisen
    out of practical developments instead of predating them.
  </blockquote>
  Indeed, one might speculate how much more natural computability theory would have
  been if Lisp has been invented thirty years earlier. Readers might want to pursue
  this topic, see the discussion in
  <a href="refs.html#{Hofstadter85}" data-v-5c36311d>{Hofstadter85}</a> starting on p 444, and his
  very startling conclusion on p 449.
  <p data-v-5c36311d>
    In Joy many metatheoretic proofs are easier still because there are no named formal
    parameters. Consequently the difficult operation of substituting actual parameters
    for formal parameters does not occur, and everything is algebra. Reasoning about
    Joy programs will now be illustrated with a number of classical theorems.
  <p data-v-5c36311d>
    A simple form of the <em data-v-5c36311d>parametrisation theorem</em> states: there is a recursive
    function taking the Gödel number of an <em data-v-5c36311d>
    n</em>-ary function F1 as one argument and taking the Gödel number of a numeral as
    a further argument such that the value of this recursive function is the Gödel
    number of an <em data-v-5c36311d> n-1</em>-ary function F2 which is obtained by substituting the
    value of the numeral for the first argument of F1.
  <p data-v-5c36311d>
    Here is the same theorem for Joy. An <em data-v-5c36311d>operand</em> is a numeral (or any other
    constant) or a quotation.
  <pre data-v-5c36311d>        For any program P and operand X
              there is a program Q such that
                  Q   ==   [Q] i  ==  X  P
  </pre>
  The required program <code data-v-5c36311d>Q</code> is just the concatenation. But the theorem
  can be strengthened:
  <pre data-v-5c36311d>        There is a program O such that
              for any program P and operand X
                  there is a program Q such that
                      X [P] O  ==  [Q] and
                      Q  ==  [Q] i  ==  X [P] i  ==  X P
  </pre>
  The required program <code data-v-5c36311d>O</code> is <code data-v-5c36311d>cons</code>:
  <pre data-v-5c36311d>        X [P] O  ==  X [P] cons  ==  [X P]  ==  [Q]
  </pre>
  The theorem is rather trivial in Joy. The formalisation of the proof is an
  overkill. However, many proofs later on will have the same structure, and it may
  help to get used to that.
  <p data-v-5c36311d>
    The parametrisation theorem generalises to any number <em data-v-5c36311d> m</em> of arguments
    that are parametrised. Consequently it is often called the
    <em data-v-5c36311d>S-m-n theorem</em>, see <a href="refs.html#{Rogers67}" data-v-5c36311d>{Rogers67}</a>. The
    "S" stands for "substitution" - it means that <em data-v-5c36311d> m</em> of the <em data-v-5c36311d> n</em> formal
    parameters are replaced by fixed values. In Joy notation repeated
    <code data-v-5c36311d>cons</code> operations can parameterise for any <em data-v-5c36311d> m</em>, simply by repeating
    <code data-v-5c36311d>cons</code><em data-v-5c36311d> m</em> times.
  <p data-v-5c36311d>
    In recursive function theory it is possible for functions to take other functions
    as parameters, and since functions are untyped, they can take themselves as parameter.
    One consequence ot the S-m-n theorem is the <em data-v-5c36311d>diagonalisation theorem</em>:
    There is a recursive function taking as argument the Gödel number of a function
    which takes at least one parameter, and giving as value the Gödel number of the
    function obtained from the given one by substituting itself for the parameter.
  <p data-v-5c36311d>
    Again, the counterpart in Joy is trivial.
  <pre data-v-5c36311d>        For any program P
              there is a program Q such that
                  [Q] i  ==  Q  ==  [P] P
  </pre>
  The required quoted <code data-v-5c36311d>[Q]</code> is <code data-v-5c36311d>[[P] P]</code>. The stronger
  form is:
  <pre data-v-5c36311d>        There is a program O such that
              for any program P
                  there is a program Q such that
                      [P] O  ==  [Q]  and
                      [Q] i  ==  Q  ==  [P] dup i  ==  [P] P
  </pre>
  The required program <code data-v-5c36311d>O</code> is <code data-v-5c36311d>dup cons</code>. Proof:
  <pre data-v-5c36311d>        [P] O  ==  [P] dup cons  ==  [P] [P] cons  ==  [[P] P]  ==  [Q]
          [Q] i  ==  [[P] P] i  ==  [P] P  ==  Q
  </pre>
  So in Joy the short program
  <pre data-v-5c36311d>        dup  cons
  </pre>
  implements diagonalisation.
  <p data-v-5c36311d>
    It may help to see diagonalisation in action for a small program:
  <pre data-v-5c36311d>        [dup reverse concat] dup cons i
      ==  [dup reverse concat] [dup reverse concat] cons i       (by dup)
      ==  [[dup reverse concat] dup reverse concat] i             (by cons)
      ==  [dup reverse concat] dup reverse concat                 (by i)
      ==  [dup reverse concat] [dup reverse concat] reverse concat(by dup)
      ==  [dup reverse concat] [concat reverse dup] concat        (by reverse)
      ==  [dup reverse concat concat reverse dup]                 (by concat)
  </pre>
  So the program <code data-v-5c36311d>[dup reverse concat]</code> diagonalised and run produces
  its own palindrome. Most programs cannot be self-applied because it would breach
  typing. But here are a few, readers might like to see what they do:
  <pre data-v-5c36311d>        []
          [reverse 42]
          [42 pop]
          [pop]
          [dup cons]
  </pre><p data-v-5c36311d>
    In <a href="refs.html#{Smullyan61}" data-v-5c36311d>{Smullyan61}</a> theory of formal systems of
    (character) strings, the
    <em data-v-5c36311d> norm</em> or diagonalisation of a string <code data-v-5c36311d>X</code> is defined to be <code data-v-5c36311d>X</code>  followed by its own Gödel number in dyadic notation. In Joy the detour via Gödel
    number is eliminated by using quotations.
  <p data-v-5c36311d>
    We now consider two reductions. The first is this:
  <pre data-v-5c36311d>        [P]  dup  i
      ==  [P]  [P]  i                     (by dup)
      ==  [P]   P                         (by i)
  </pre>
  The second is this:
  <pre data-v-5c36311d>        [P]  dup  cons  i
      ==  [P]  [P]  cons  i               (by dup)
      ==  [[P]  P]  i                     (by cons)
      ==  [P]  P                          (by i)
  </pre>
  So the two reductions come to the same, and hence their first lines are identical:
  <pre data-v-5c36311d>        [P]  dup  i   ==   [P]  dup  cons  i
  </pre>
  But this holds for all <code data-v-5c36311d>[P]</code>. So we may infer
  <pre data-v-5c36311d>        dup  cons  i   ==   dup  i
  </pre><h2 data-v-5c36311d>The fixpoint theorem and the y combinator</h2>
  An important result in computability is the <em data-v-5c36311d>recursion theorem</em>, see for
  example
  <a href="refs.html#{Rogers67}" data-v-5c36311d>{Rogers67}</a>. It states:
  <blockquote data-v-5c36311d>
    For every function P there is a Gödel number of a function Q such that the result
    of applying the function P to the Gödel number of Q is the Gödel number of a function
    identical with Q.
  </blockquote>
  The theorem says that for every function P which is used to edit code for computing
  functions, there is a program Q which will compute the same function before and after
  the editing. So Q is a fixpoint, a program not affected by P. Fixpoint theorems are
  about programs
  <code data-v-5c36311d>P</code> (rather than about the functions which they compute).
  <p data-v-5c36311d>
    Here is an equivalent version for Joy:
  <pre data-v-5c36311d>        For any program P
              there is a program Q such that
                  [Q] i   ==   Q   ==   [Q] P
  </pre>
  The required program <code data-v-5c36311d>Q</code> is
  <pre data-v-5c36311d>        [dup cons P] dup cons P
  </pre>
  The proof is as follows:
  <pre data-v-5c36311d>        [            Q           ]  i
      ==  [[dup cons P]  dup cons P]  i                   (def Q)
      ==   [dup cons P]  dup cons P                       (by i)
      ==   [dup cons P] [dup cons P] cons P               (by dup)
      ==  [[dup cons P]  dup cons P]  P                   (by cons)
      ==  [            Q           ]  P                   (def Q)
  </pre><p data-v-5c36311d>
    The theorem may be strengthened. The transformation from
    <code data-v-5c36311d>P</code> to <code data-v-5c36311d>Q</code> can be done by a simple program
    <code data-v-5c36311d>O</code>:
  <pre data-v-5c36311d>        There is a program O such that
              for any program P
                  there is a program Q such that
                      [P] O   ==   [Q]   and
                      [Q] i   ==   Q   ==   [Q] P
  </pre>
  The required program <code data-v-5c36311d>O</code> is
  <pre data-v-5c36311d>        [dup cons]  swap  concat  dup  cons
  </pre>
  The proof is as follows:
  <pre data-v-5c36311d>        [P] O
      ==  [P]  [dup cons]  swap  concat  dup  cons        (def O)
      ==  [dup cons]  [P]        concat  dup  cons        (by swap)
      ==  [dup cons P]                   dup  cons        (by concat)
      ==  [dup cons P]  [dup cons P]          cons        (by dup)
      ==  [[dup cons P] dup cons P]                       (by cons)
      ==  [Q]                                             (def Q)
  </pre>
  The fixpoint finding program <code data-v-5c36311d>O</code> is useful: henceforth it will
  be called the <kbd data-v-5c36311d>fix</kbd> operator. We also define the
  <kbd data-v-5c36311d>y</kbd> combinator for Joy:
  <pre data-v-5c36311d>        y   ==   fix  i
  </pre>
  This is the Joy counterpart of Curry's "paradoxical" <em data-v-5c36311d>Y
  combinator</em> (uppercase), see <a href="refs.html#{Curry58}" data-v-5c36311d>{Curry58}</a>. This
  combinator is well known in the literature on the lambda calculus and on combinatory
  logic.
  <p data-v-5c36311d>
    The recursion theorem traces its ancestry to Epimenides, Russell and Grelling (for
    <code data-v-5c36311d>[P]</code> put <code data-v-5c36311d>[i not]</code>, and to Gödel. In its general form
    it is due to Kleene. Its proof is very cumbersome in just about all formalisms.
    As can be seen from the above, in Joy the proof is very simple.
  <p data-v-5c36311d>
    The S-m-n theorem is the basis for <em data-v-5c36311d>partial evaluation</em> or
    <em data-v-5c36311d>program specialisation</em>. A special case for this is the partial evaluator
    <em data-v-5c36311d>mix</em> which can transform an interpreter into a compiler, and can transform
    itself into a compiler generator.
    <a href="refs.html#{Jones92}" data-v-5c36311d>{Jones92}</a> shows that such transformations can
    be done realistically only if the partial evaluator has primitives in terms of
    which the fixpoint constructions of the recursion theorem can be implemented efficiently.
    The two primitives chosen are in fact very close to Joy's <code data-v-5c36311d>i</code> combinator
    and quotation.
  <p data-v-5c36311d>
    The recursion theorem leads in a few steps to Rice's theorem, see
    <a href="refs.html#{Rogers67}" data-v-5c36311d>{Rogers67}</a>, which encapsulates all the bad news
    of computability theory: for example the <em data-v-5c36311d>halting problem</em>, or the impossibility
    of writing programs which check other programs - implementation, student exercises
    - for correctness.
  <h2 data-v-5c36311d>Some simple cases</h2>
  The theorem, in both forms, speaks of <em data-v-5c36311d> all</em> programs
  <code data-v-5c36311d>P</code>. It is of some interest to see what happens when some simple actual
  programs are chosen. Two particularly simple programs are
  <ol data-v-5c36311d><li data-v-5c36311d> the empty program, which computes the identity function, and
    <li data-v-5c36311d> the <code data-v-5c36311d>i</code> combinator program, which dequotes and executes a program on
      top of the stack.
    </ol><p data-v-5c36311d><ol data-v-5c36311d><li data-v-5c36311d>
      A frequently paraded corollary of the recursion theorem is the existence of <em data-v-5c36311d>self-reproducing program</em>s.
      When run, these program produce a replica of themselves. A suitably general definition
      of self-reproducing programs is this: a program
      <code data-v-5c36311d>S</code> is self-reproducing if this conditions holds:
      <pre data-v-5c36311d>        S  i   ==   S
  </pre>
      Note that <code data-v-5c36311d>S</code> is allowed to be arbitrarily complex, it does
      not have to be just a quoted program. Such programs are obtained from the recursion
      theorem by making <code data-v-5c36311d>P</code> compute the identity function. In Joy this is
      represented most simply by the empty program, in quoted form <code data-v-5c36311d>[]</code>.
      (Alternatively, it is represented by the program <code data-v-5c36311d>id</code>, in quoted form
      <code data-v-5c36311d>[id]</code>.)
      <pre data-v-5c36311d>        There is a program Q such that
              [Q] i   ==   [Q]
  </pre>
      Proof: let <code data-v-5c36311d>Q</code> be the program
      <pre data-v-5c36311d>            [dup cons] dup cons
  </pre>
      Then the derivation is as follows:
      <pre data-v-5c36311d>        [[dup cons]  dup cons]  i
      ==   [dup cons]  dup cons                           (by i)
      ==   [dup cons] [dup cons] cons                     (by dup)
      ==  [[dup cons]  dup cons]                          (by cons)
  </pre>
      Readers might like to be reminded of a self-replicating C-program:
      <pre data-v-5c36311d>  p="p=%c%s%c;main(){printf(p,34,p,34);}";main(){printf(p,34,p,34);}
  </pre>
      (Author unknown. Proving correctness is not easy.)
      <p data-v-5c36311d>
        Related to self-reproducing programs are <em data-v-5c36311d>self-describing
        program</em>s. A program <code data-v-5c36311d>S</code> is self-describing if running it produces
        a description of it. In Joy a program <code data-v-5c36311d>S</code> is self-describing if
        this condition holds:
      <pre data-v-5c36311d>        S   ==   [S]
  </pre>
      Here is a self-describing program:
      <pre data-v-5c36311d>        [dup cons] dup cons
      ==  [dup cons] [dup cons] cons                      (by dup)
      ==  [[dup cons] dup cons]                           (by cons)
  </pre><p data-v-5c36311d><li data-v-5c36311d>
      The other simple program to investigate is the <code data-v-5c36311d>i</code> combinator. Then
      <code data-v-5c36311d>[P]</code> is <code data-v-5c36311d>[i]</code>, and
      <code data-v-5c36311d>[Q]</code> is <code data-v-5c36311d>[[dup cons i] dup cons i]</code>. This is what happens:
      <pre data-v-5c36311d>        [[dup cons i]  dup cons i]  i
      ==   [dup cons i]  dup cons i                       (by i)
      ==   [dup cons i] [dup cons i]  cons i              (by dup)
      ==  [[dup cons i]  dup cons i]  i                   (by cons)
  </pre>
      So this is a program that runs forever. This is the Joy counterpart of
      what in the lambda calculus is selfapplication selfapplied. In both the reductions
      do not terminate. In the lambda calculus the rule used is beta-reduction, the
      substitution of actual for formal parameters. In Joy there are no formal parameters,
      just algebraic simplification.
      <p data-v-5c36311d>
        The <code data-v-5c36311d>dup cons</code> combination occurs so frequently that it is worth
        introducing an operator <kbd data-v-5c36311d>duco</kbd> defined by
      <pre data-v-5c36311d>        duco   ==   dup  cons
  </pre>
      This will make proofs shorter both horizontally (because programs are shorter)
      and vertically (because two steps are condensed into one).
      <p data-v-5c36311d><li data-v-5c36311d>
      The next kind of program is with <code data-v-5c36311d>[P]</code> =
      <code data-v-5c36311d>dup</code>. Then <code data-v-5c36311d>[Q]</code> is the quotation in the first line below,
      and execution is as follows:
      <pre data-v-5c36311d>        [[duco dup] duco dup]  i
      ==   [duco dup] duco dup                            (by i)
      ==  [[duco dup] duco dup] dup                       (by duco)
      ==  [[duco dup] duco dup] [[duco dup] duco dup]     (by dup)
  </pre>
      So this is an example of a program which when run produces two copies
      of itself. The program in the second line is another
      <em data-v-5c36311d>self-describing program</em>, it produces two copies of itself.
      <p data-v-5c36311d><li data-v-5c36311d>
      The next program uses <code data-v-5c36311d>[P]</code> = <code data-v-5c36311d>dup i</code>. Then execution starts
      like this:
      <pre data-v-5c36311d>        [[duco dup i] duco dup i]  i
      ==   [duco dup i] duco dup i                                (by i)
      ==  [[duco dup i] duco dup i] dup i                         (by duco)
      ==  [[duco dup i] duco dup i] [[duco dup i] duco dup i] i   (by dup)
  </pre>
      So this is another program that runs forever. In addition it leaves earlier
      copies of itself on the stack. In an implementation it must run out of stack
      space. The program in the second line is again self-describing, but it never
      finishes what would be a description of infinitely many copies of itself.
      <p data-v-5c36311d>
        Another program that does much the same is
      <pre data-v-5c36311d>        [[duco dup dip] duco dup dip]
  </pre><p data-v-5c36311d><li data-v-5c36311d>
      In the introduction a program was given which computes the factorial function without
      being defined recursively. Here are the first few steps in the execution of that
      program, those that are independent of the numeric parameter that is provided
      to the program. To save space, the <code data-v-5c36311d>duco</code> operator is used.
      <pre data-v-5c36311d>        [ [pop 0 =] [pop pop 1] [[dup 1 -] dip i *] ifte ]
          y
      ==  [ [pop 0 =] [pop pop 1] [[dup 1 -] dip i *] ifte ]
          fix  i                                                  (by y)
      ==  [ [pop 0 =] [pop pop 1] [[dup 1 -] dip i *] ifte ]
          [duco] swap concat duco  i                              (def fix)
      ==  [duco] [ [pop 0 =] [pop pop 1] [[dup 1 -] dip i *] ifte ]
          concat duco  i                                          (by swap)
      ==  [ duco [pop 0 =] [pop pop 1] [[dup 1 -] dip i *] ifte ]
          duco  i                                                 (by concat)
      ==  [[ duco [pop 0 =] [pop pop 1] [[dup 1 -] dip i *] ifte ]
             duco [pop 0 =] [pop pop 1] [[dup 1 -] dip i *] ifte ]
          i                                                       (by duco)
      ==  [ duco [pop 0 =] [pop pop 1] [[dup 1 -] dip i *] ifte ]
          duco [pop 0 =] [pop pop 1] [[dup 1 -] dip i *] ifte     (by i)
      ==  [[ duco [pop 0 =] [pop pop 1] [[dup 1 -] dip i *] ifte ]
             duco [pop 0 =] [pop pop 1] [[dup 1 -] dip i *] ifte ]
          [pop 0 =] [pop pop 1] [[dup 1 -] dip i *] ifte          (by duco)
  </pre>
      At this point the numeric parameter for the computation will be needed.
      The <code data-v-5c36311d>ifte</code> combinator will execute its if-part. That results in the
      long two-line quotation being popped off the stack and the parameter being compared
      with 0. If that evaluates to
      <code data-v-5c36311d>true</code>, the then-part is executed with the parameters and the two-line
      quotation still on top of the stack, The then-part pops both and replaces them
      by 1. But if the if-part returns
      <code data-v-5c36311d>false</code>, the else-part is executed, again with the parameter and the
      two-line quotation on top of the stack.
      <p data-v-5c36311d>
        First the two-line quotation is set aside by <code data-v-5c36311d>dip</code>, the parameter
        is duplicated and the top copy decremented. Only then the two-line quotation
        will be executed by <code data-v-5c36311d>i</code>. The effect is to construct a clone of itself
        with <code data-v-5c36311d>duco</code>, pushing the same if-part, then-part and else-part for
        the contained
        <code data-v-5c36311d>ifte</code>. When that eventually returns, the old parameter and above
        it the factorial of the decremented parameter copy are finally multiplied to
        give the required factorial of the original parameter.
      </ol><h2 data-v-5c36311d>Evaluation order</h2>
  Most theoretical and practical programming languages use <em data-v-5c36311d>formal
  parameter</em>s in definitions of functions (and procedures). These functions are
  called with expressions as the <em data-v-5c36311d>actual
  parameter</em>s. There are two ways of doing this: <em data-v-5c36311d>normal
  order</em>, also known as <em data-v-5c36311d>call by name</em>, and <em data-v-5c36311d>applicative
  order</em>, also known as <em data-v-5c36311d>call by value</em>. In normal order the unevaluated
  expressions are substituted for the formal parameters, and the expressions will be
  evaluated only if the body of the function requires it.
  <p data-v-5c36311d>
    In applicative order the expressions are evaluated first and that value is substituted
    for the formal parameter. If the value of a parameter expression is used repeatedly
    in the body of the function, then normal order requires repeated evaluation of
    the expression, whereas applicative order requires only one evaluation. On the
    other hand, if the body does not require the value at all, then applicative order
    will have wasted time trying to evaluate the expression. If that evaluation does
    not terminate at all, then the call of the function will fail to terminate under
    applicative order although it would have terminated under normal order. Consequently
    there are some functions that are less defined under applicative order evaluation
    than they are under normal order.
  <p data-v-5c36311d>
    The Y combinator of the lambda calculus does not work at all for applicative order.
    No matter what the function is, the call with the Y combinator will try to do the
    unending sequence of substitutions and hence fail to terminate. Therefore a different
    version of the Y combinator has to be used, see <a href="refs.html#{Stoy77}" data-v-5c36311d>{Stoy77}</a>,
    <a href="refs.html#{Henson87}" data-v-5c36311d>{Henson87}</a>, <a href="refs.html#{Paulson92}" data-v-5c36311d>{Paulson92}</a>,
    <a href="refs.html#{Winskel93}" data-v-5c36311d>{Winskel93}</a>.
  <p data-v-5c36311d>
    In Joy there are no formal parameters, there is no substitution, and hence strictly
    speaking there is no evaluation order. Joy functions take their actual parameters
    as values from the stack, and in a way this <em data-v-5c36311d> resembles</em> applicative order.
    The <code data-v-5c36311d>y</code> combinator of Joy always terminates correctly provided that
    the quoted program and any of its actual parameters did get onto the stack, and
    provided that the quoted program terminates. So there is a difference between the
    Y combinator of the lambda calculus under applicative order, and the <code data-v-5c36311d>y</code>  combinator of Joy. What is the reason? Consider again, for an arbitrary program
    <code data-v-5c36311d>[P]</code><pre data-v-5c36311d>        [P]  y
      ==  [P]  fix  i
      ==  [[duco P] duco P]  i
      ==  [duco P]  duco P
      ==  [[duco P] duco P]  P
  </pre>
  This point is always reached in the initial call, and it is independent of
  what <code data-v-5c36311d>P</code> actually is. At this point there is a (double) quotation (containing
  <code data-v-5c36311d>P</code> twice) on top of the stack, and <code data-v-5c36311d>P</code> now has it available
  as a parameter. Quotations are never evaluated further, although they can be explicitly
  manipulated by operators or they can be explicitly called by combinators. Consequently
  the second <code data-v-5c36311d>duco</code> inside the quotation will <em data-v-5c36311d> not</em> be executed
  to yield
  <pre data-v-5c36311d>    ==  [[[duco P] duco P] duco P]  P
  </pre>
  Here of course the second and third <code data-v-5c36311d>duco</code> would have been the
  next candidates for execution, and so on. So the reason for the difference is that
  quotations in Joy are never evaluated automatically, whereas abstractions in the
  lambda calculus will be under applicative order evaluation.
  <p data-v-5c36311d>
    It is possible to generalise fixpoint combinators for mutual recursion. For the lambda
    calculus this is done for example by
    <a href="refs.html#{Kogge91}" data-v-5c36311d>{Kogge91}</a>, shows how pairs of mutually recursive
    definitions can be eliminated by using a pair of rather complicated mutually recursive
    combinators Y1 and Y2. A similar technique is explained in
    <a href="refs.html#{Henson87}" data-v-5c36311d>{Henson87}</a>. Constructions such as these rely
    on the existence of
    <em data-v-5c36311d>double fixpoints</em>, whose existence follows from a <em data-v-5c36311d>double
    recursion theorem</em> (see for example <a href="refs.html#{Smullyan94}" data-v-5c36311d>{Smullyan94}</a>).
    Presumably these can be translated into Joy, too.
  <h2 data-v-5c36311d>Rice's theorem</h2>
  Consider arbitrary sets of functions, and note that this does not mean sets of programs.
  Call such a set <em data-v-5c36311d> non-trivial</em> if it is neither the universal set of all functions
  nor the null set of no functions. Given a non-trivial set <code data-v-5c36311d>F</code> of partial
  functions and a Joy program <code data-v-5c36311d>[Q]</code>, the question arises whether the function
  computed by <code data-v-5c36311d>[Q]</code> is in <code data-v-5c36311d>F</code> or not. Is there an algorithm for
  deciding such questions? More specifically, is there a Joy program, say <code data-v-5c36311d>PF</code>,
  for deciding such questions? Such a program would have to satisfy
  <pre data-v-5c36311d>    [Q]  PF   ==   true,  if the function computed by [Q] is in F
                ==   false, if the function computed by [Q] is not in F
  </pre>
  The program <code data-v-5c36311d>PF</code> is also expected to terminate for all inputs <code data-v-5c36311d>[Q]</code>.
  Can there be such a program?
  <p data-v-5c36311d>
    No. This is <em data-v-5c36311d>Rice's theorem</em>:
  <pre data-v-5c36311d>        For all non-trivial sets F of partial functions,
              there is no program  PF  such that
                  for all programs  Q
                      PF can decide whether
                          the function computed by  Q  is in F.
  </pre>
  Proof: Let <code data-v-5c36311d>F</code> be a non-trivial set of functions. Since
  <code data-v-5c36311d>F</code> is non-trivial, there are some functions in
  <code data-v-5c36311d>F</code> and some functions not in <code data-v-5c36311d>F</code>. Let program
  <code data-v-5c36311d>[E]</code> compute a function in <code data-v-5c36311d>F</code> and let
  <code data-v-5c36311d>[E']</code> compute a function not in <code data-v-5c36311d>F</code>.
  <p data-v-5c36311d>
    Now assume that a program <code data-v-5c36311d>PF</code> exists, and that it always terminates.
    Next, consider the following Joy program:
  <pre data-v-5c36311d>        [PF]  [pop [E']]  [pop [E]]  ifte
  </pre>
  The program expects an arbitrary program <code data-v-5c36311d>[Q]</code> on top of the stack
  and then pushes the three small quotations. The
  <kbd data-v-5c36311d>ifte</kbd> operator then removes them again and executes the first short quotation
  <code data-v-5c36311d>[PF]</code>. This will result in a truth value, <code data-v-5c36311d>true</code> or <code data-v-5c36311d>false</code>.
  In the first case the second short quotation is executed, it <code data-v-5c36311d>pop</code>s the
  <code data-v-5c36311d>[PF]</code> and replaces it by <code data-v-5c36311d>[E']</code>. In the second case the third
  short quotation is executed, it <code data-v-5c36311d>pop</code>s the
  <code data-v-5c36311d>[PF]</code> and replaces it by <code data-v-5c36311d>[E]</code>. So, if
  <code data-v-5c36311d>[Q]</code> is in <code data-v-5c36311d>F</code>, the program returns a program not in <code data-v-5c36311d>F</code>,
  namely <code data-v-5c36311d>[E']</code>. On the other hand, if <code data-v-5c36311d>[Q]</code> is not in <code data-v-5c36311d>F</code>,
  the program returns a program that is in <code data-v-5c36311d>F</code>, namely <code data-v-5c36311d>[E]</code>.
  In other words, no matter what the input program <code data-v-5c36311d>[Q]</code> is, the output
  program is opposite as far as membership in <code data-v-5c36311d>F</code> is concerned. Call the
  above program <code data-v-5c36311d>OPF</code>.
  <p data-v-5c36311d>
    By the fixpoint theorem, the program <code data-v-5c36311d>OPF</code> must have a fixpoint, say
    <code data-v-5c36311d>FIXOPF</code>, satisfying
  <pre data-v-5c36311d>        FIXOPF  ==  [FIXOPF]  OPF
  </pre>
  But if the program on the left computes a function in <code data-v-5c36311d>F</code>, then
  the program on the right computes a function not in
  <code data-v-5c36311d>F</code>, and vice versa. But this is a contradiction. So the program <code data-v-5c36311d>OPF</code>fails for at least one program, its own fixpoint <code data-v-5c36311d>FIXOPF</code>. We must conclude
  that the assumption was false. So there cannot be a program <code data-v-5c36311d>PF</code>.
  <p data-v-5c36311d>
    The above proof of Rice's theorem for Joy is adapted from a proof for recursive functions
    in <a href="refs.html#{Phillips92}" data-v-5c36311d>{Phillips92}</a>. Several well-known
    <em data-v-5c36311d>paradox</em>es are instances of the recursion theorem, for example the <em data-v-5c36311d>Liar paradox</em>  and <em data-v-5c36311d>Grelling's paradox</em> use as the program <code data-v-5c36311d>[P]</code> the simple
    program <code data-v-5c36311d>[i not]</code>. Recent discussions of the Liar and related problems
    can be found in
    <a href="refs.html#{Martin70}" data-v-5c36311d>{Martin70}</a> and in <a href="refs.html#{Barwise-Etchemendy87}" data-v-5c36311d>{Barwise-Etchemendy87}</a>.
  <h2 data-v-5c36311d>Other self-reproducing and self-describing programs</h2>
  There are variants of the programs in section 5 which are worth mentioning.
  <ol data-v-5c36311d><li data-v-5c36311d>
      The following is a simplification of the first self-reproducing program. It is simpler
      because it uses an operand parameter which it leaves intact.
      <pre data-v-5c36311d>        There is an operand Q1 and a program Q2 such that
              Q1  [Q2]  i   ==   Q1  [Q2]
  </pre>
      Proof: Let <code data-v-5c36311d>Q1</code> = <code data-v-5c36311d>[dup]</code> and let
      <code data-v-5c36311d>Q2</code> = <code data-v-5c36311d>dup</code>. Then the derivation is
      <pre data-v-5c36311d>        [dup]  [dup]  i
      ==  [dup]   dup                             (by i)
      ==  [dup]  [dup]                            (by dup)
  </pre>
      This seemingly trivial self-reproducing program will be used to derive
      a version of recursion that is actually more efficient than the one based on
      the <code data-v-5c36311d>y</code> combinator.
      <p data-v-5c36311d><li data-v-5c36311d>
      The next uses the <code data-v-5c36311d>b</code> combinator:
      <pre data-v-5c36311d>        There are programs Q1 and Q2 such that
              [Q1] [Q2] b   ==   [Q1] [Q2]
  </pre>
      Proof: let Q1 and Q2 be the programs
      <pre data-v-5c36311d>        [[] cons dup first]
           [] cons dup first
  </pre>
      Then the derivation is:
      <pre data-v-5c36311d>        [[[] cons dup first]]  [[] cons dup first]  b
      ==   [[] cons dup first]    [] cons dup first           (by b)
      ==  [[[] cons dup first]]           dup first           (by cons)
      ==  [[[] cons dup first]] [[[] cons dup first]] first   (by dup)
      ==  [[[] cons dup first]]  [[] cons dup first]          (by first)
  </pre>
      It is useful to introduce an operator <kbd data-v-5c36311d>codufi</kbd> by the definition:
      <pre data-v-5c36311d>        codufi  ==  cons dup first
  </pre>
      The operator will be found useful in the next section.
      <p data-v-5c36311d><li data-v-5c36311d>
      The next example of a self-reproducing program again uses the
      <code data-v-5c36311d>i</code> combinator:
      <pre data-v-5c36311d>        There is a program Q such that
                  [Q] i i   ==   [Q]   =/=   [Q] i
  </pre>
      Proof: let <code data-v-5c36311d>Q</code> be the program
      <pre data-v-5c36311d>        [duco [] cons] duco [] cons
  </pre>
      The execution now looks like this:
      <pre data-v-5c36311d>         [[duco [] cons] duco [] cons]   i  i
      ==    [duco [] cons] duco [] cons  i                        (by i)
      ==   [[duco [] cons] duco [] cons] [] cons  i               (by duco)
      ==  [[[duco [] cons] duco [] cons]]  i                      (by cons)
      ==   [[duco [] cons] duco [] cons]                          (by i)
  </pre>
      Observe that the quoted programs in the first and fourth line differ by
      just the extra quoting in line four.
      <p data-v-5c36311d>
        There is another program with the property. Let <code data-v-5c36311d>Q</code> be the program
      <pre data-v-5c36311d>        [false [not] infra dup rest cons] [not] infra dup rest cons
  </pre>
      The combinator <kbd data-v-5c36311d>infra</kbd> expects a program (here
      <code data-v-5c36311d>[not]</code>) on top of the stack, and below that a quotation (here the
      first half of the program). It temporarily turns the quotation into the stack
      and executes the program (here it complements the truth value <code data-v-5c36311d>false</code>    or <code data-v-5c36311d>true</code> at the very beginning. An outline of the derivation is:
      <pre data-v-5c36311d>    [[false [not] infra dup rest cons] [not] infra dup rest cons] i i
      [[true  [not] infra dup rest cons] [not] infra dup rest cons] i
      [[false [not] infra dup rest cons] [not] infra dup rest cons]
  </pre>
      (Each by 5 steps)
      <p data-v-5c36311d>
        The quoted programs the first and second lines are examples of
        <em data-v-5c36311d>mutually describing programs</em>, satisfying
      <pre data-v-5c36311d>        P  =  [Q]       and       Q  == [P]
  </pre>
      In detail:
      <pre data-v-5c36311d>P  ==  [false [not] infra dup rest cons] [not] infra dup rest cons
  Q  ==  [true  [not] infra dup rest cons] [not] infra dup rest cons
  </pre><li data-v-5c36311d>
      The previous program keeps an internal toggle (<code data-v-5c36311d>true</code> or
      <code data-v-5c36311d>false</code>) which is thrown every time it is called. The next program
      does the same with a counter, and consequently every generation is different
      from all previous ones: Let <code data-v-5c36311d>Q</code> be the program
      <pre data-v-5c36311d>    [0 [1 +] infra dup rest cons] [1 +] infra dup rest cons
  </pre>
      Successive executions using <code data-v-5c36311d>i</code> cause the <code data-v-5c36311d>0</code> to
      be incremented to <code data-v-5c36311d>1</code>, <code data-v-5c36311d>2</code> and so on.
      <p data-v-5c36311d><li data-v-5c36311d>
      Almost all programs become ruined when maltreated. Cutting off bits and pieces would
      generally cause malfunction. Worms of course can regenerate from small pieces,
      but most programs are not like that. But programs can be written so that after
      each call they become more and more insensitive to mutilation. The mutilating
      operations are
      <code data-v-5c36311d>first</code> and <code data-v-5c36311d>rest</code> or sequences of such operations. There
      are programs which with every generation become less and less sensitive to longer
      and longer sequences of mutilations. Two such <code data-v-5c36311d>Q</code> are
      <pre data-v-5c36311d>        [duco duco] duco duco
          [cons duco] [cons duco] cons duco
  </pre><p data-v-5c36311d><li data-v-5c36311d>
      Kym Horsell commented that self-reproducing programs do not do anything useful. The
      idea would be that for a given program another program is to be found which is
      self-reproducing and at each generation executes the original program first.
      So the problem is to find, for arbitrary <code data-v-5c36311d>P</code>, a program <code data-v-5c36311d>Q</code>    such that
      <pre data-v-5c36311d>        [Q]  i  i  ..  i   ==   P  P  ..  P  [Q]
  </pre>
      where the <code data-v-5c36311d>i</code> on the left and the <code data-v-5c36311d>P</code> on the right
      are repeated the same number of times. Here is one answer:
      <pre data-v-5c36311d>        There is a program O such that
              for all programs P
                  there is a program Q such that
                          [P]  O   ==   [Q]   and
                          [Q]  i   ==   Q   ==   P  [Q]
  </pre>
      Proof: Let <code data-v-5c36311d>O</code> be the program
      <pre data-v-5c36311d>        [dup [first i] dip rest duco] cons duco
  </pre>
      Then for any <code data-v-5c36311d>P</code>:
      <pre data-v-5c36311d>    [P]  O
  ==  [P] [dup [first i] dip rest duco] cons duco         (by O)
  ==  [[P] dup [first i] dip rest duco] duco              (by cons)
  == [[[P] dup [first i] dip rest duco] [P] dup [first i] dip rest duco]
                                                          (by duco)
  </pre></ol><h2 data-v-5c36311d>Another recursion combinator</h2>
  Apart from the <code data-v-5c36311d>y</code> combinator there are other recursion combinators.
  One of them is given by the following theorem:
  <pre data-v-5c36311d>        There is a program M such that
  (1)         [y] M  ==  [y] i  ==  y  and
              for some programs N and O
  (2a)             [M] [duco] swap concat  ==  [N]  and
  (2b)             [N] duco  ==  [O] and
  (3)              [M] y  ==  [N] dup i  ==  O  and
                   for all programs P
  (4)                  [P] O  ==  [P] y  and
                       there is a program Q such that
  (5)                     [P] [O] cons  ==  [Q]  and
  (6)                     [Q] i  ==  Q  ==  [Q] P
  </pre>
  The first line, (1), says that <code data-v-5c36311d>y</code> is a fixpoint for
  <code data-v-5c36311d>M</code>. Lines (2a) and (2b) show how to construct two further programs <code data-v-5c36311d>N</code>and <code data-v-5c36311d>O</code>. Line (3) expresses a relationship between the three programs
  <code data-v-5c36311d>M</code>, <code data-v-5c36311d>N</code> and <code data-v-5c36311d>O</code>. Line (5) shows how to construct
  a program
  <code data-v-5c36311d>Q</code> which depends on <code data-v-5c36311d>P</code>. The last line of the theorem says
  that the <code data-v-5c36311d>Q</code> is a fixpoint for <code data-v-5c36311d>P</code>.
  <p data-v-5c36311d><b data-v-5c36311d>Proof:</b> Only <code data-v-5c36311d>M</code> need be given, because
    <code data-v-5c36311d>N</code> and <code data-v-5c36311d>O</code> are constructed. The required
    <code data-v-5c36311d>M</code> is actually a combinator already seen in section 2:
  <pre data-v-5c36311d>        cons  dup  first  i
  </pre>
  But the first three operators can be replaced by <kbd data-v-5c36311d>codufi</kbd> defined
  in the previous section. So we set:
  <pre data-v-5c36311d>        M  ==  codufi i
  </pre>
  This is used to construct <code data-v-5c36311d>N</code>:
  <pre data-v-5c36311d>        [M] [duco] swap concat
      ==  [codufi i] [duco] swap concat                           (def M)
      ==  [duco] [codufi i]                                       (by swap)
      ==  [duco codufi i]                                         (by concat)
      ==  [N]                                                     (def N)
  </pre>
  So we have:
  <pre data-v-5c36311d>        N  ==  duco codufi i
  </pre>
  This program can be used to construct <code data-v-5c36311d>O</code>:
  <pre data-v-5c36311d>        [N] duco
      ==  [duco codufi i] duco                                    (def N)
      ==  [[duco codufi i] duco codufi i]                         (by duco)
      ==  [O]                                                     (def O)
  </pre>
  So we have:
  <pre data-v-5c36311d>        O  ==  [duco codufi i] duco codufi i
  </pre>
  This program can now be used to construct, for arbitrary
  <code data-v-5c36311d>[P]</code> a corresponding <code data-v-5c36311d>[Q]</code>:
  <pre data-v-5c36311d>        [P] [O] cons
      ==  [P] [[duco codufi i] duco codufi i] cons                (def O)
      ==  [[P] [duco codufi i] duco codufi i]                     (by cons)
      ==  [Q]                                                     (def Q)
  </pre>
  So we have, for arbitrary <code data-v-5c36311d>[P]</code>,
  <pre data-v-5c36311d>        Q  ==  [P] [duco codufi i] duco codufi i
  </pre>
  It remains to be shown that <code data-v-5c36311d>Q</code> is a fixpoint for <code data-v-5c36311d>P</code>:
  <pre data-v-5c36311d>        [Q]  i
      ==  [[P] [duco codufi i] duco codufi i]  i                  (def Q)
      ==   [P] [duco codufi i] duco codufi i                      (by i)
      ==  [P] [[duco codufi i] duco codufi i] codufi i            (by duco)
      ==  [[P] [duco codufi i] duco codufi i] [P] i               (by codufi)
      ==  [[P] [duco codufi i] duco codufi i]  P                  (by i)
      ==  [Q]  P                                                  (def Q)
  </pre>
  This shows that <code data-v-5c36311d>Q</code> is indeed a fixpoint for <code data-v-5c36311d>P</code>.
  <p data-v-5c36311d>
    Different recursion combinators, and indeed a whole hierarchy of them, are well known
    in the literature on <em data-v-5c36311d>lambda calculus</em> and
    <em data-v-5c36311d>combinatory logic</em>; see for example <a href="refs.html#{Barendregt84}" data-v-5c36311d>{Barendregt84}</a>,
    <a href="refs.html#{Henson87}" data-v-5c36311d>{Henson87}</a>, <a href="refs.html#{Revesz88}" data-v-5c36311d>{Revesz88}</a>.
    Possibly one of the most satisfying introductions to combinatory logic is to be
    found in the remarkable little book <a href="refs.html#{Smullyan90}" data-v-5c36311d>{Smullyan90}</a><em data-v-5c36311d> To Mock a Mockingbird</em> in which he manages to combine humour and rigour.
    Part III is a self-contained exposition to combinatory logic in which fancyful
    names are given to lambda calculus combinators.
  <h2 data-v-5c36311d>Practical recursion combinators in Joy</h2>
  Here are three recursive definitions. The function
  <code data-v-5c36311d>r-last</code> finds the <em data-v-5c36311d>last</em> element of a list. The function <code data-v-5c36311d>r-fac</code>computes the <em data-v-5c36311d>factorial</em> of a number. The function <code data-v-5c36311d>r-fib</code> computes
  the
  <em data-v-5c36311d>Fibonacci</em> value of a number.
  <pre data-v-5c36311d>    r-last  ==  [rest null] [first] [rest r-last] ifte
      r-fac  ==  [0 =] [succ] [dup pred r-fac *] ifte
      r-fib  ==  [small] [pop 1] [pred dup pred [r-fib] app2 +] ifte
  </pre>
  The following three functions also compute The last, the factorial and the
  Fibonacci of their parameter. Note that there is no definition; the recursion is
  taken care of by the <code data-v-5c36311d>y</code> combinator.
  <pre data-v-5c36311d>  [ [pop rest null] [pop first] [[rest] dip i] ifte ] y
    [ [pop 0 =] [pop succ] [[dup pred] dip i *] ifte ] y
    [ [pop small] [pop pop 1] [[pred dup pred] dip app2 +] ifte] y
  </pre><p data-v-5c36311d>
    But the <code data-v-5c36311d>y</code> combinator is intrisically inefficient because of the way
    it operates. On every recursive call a certain program is popped off the stack
    to be executed. The first task of that program is to construct a copy of itself,
    in readiness for any further recursive calls. But this is really quite silly. It
    would be better more efficient if the program to be executed was <em data-v-5c36311d> not</em>  popped off the stack at all but simply left there. Whereas most combinators remove
    their parameters from the stack, a new <kbd data-v-5c36311d>x</kbd> combinator leaves it there
    as a parameter for itself.
  <p data-v-5c36311d>
    The following programs use the <code data-v-5c36311d>x</code> combinator instead of the <code data-v-5c36311d>y</code>  combinator. They are obtained from the first two of the previous programs by replacing
    the internal occurrences of the
    <code data-v-5c36311d>i</code> combinator and the the external occurrence of the
    <code data-v-5c36311d>y</code> combinator by the <code data-v-5c36311d>x</code> combinator.
  <pre data-v-5c36311d>  [ [pop rest null] [pop first] [[rest] dip x] ifte ] x
    [ [pop 0 =] [pop succ] [[dup pred] dip x *] ifte ] x
  </pre>
  The <code data-v-5c36311d>x</code> combinator <em data-v-5c36311d> might</em> have been defined by
  <pre data-v-5c36311d>        x  ==  dup i
  </pre><p data-v-5c36311d>
    Similar lambda calculus constructions are discussed in <a href="refs.html#{Tennent76}" data-v-5c36311d>{Tennent76}</a>,
    <a href="refs.html#{Bauer-Woessner82}" data-v-5c36311d>{Bauer-Woessner82}</a>, <a href="refs.html#{Schmidt86}" data-v-5c36311d>{Schmidt86}</a>  and <a href="refs.html#{Tennent91}" data-v-5c36311d>{Tennent91}</a>.
  <p data-v-5c36311d>
    The remainder of this section describes some further general and particular combinators
    of Joy which can be used to avoid recursive definitions.
  <p data-v-5c36311d><ol data-v-5c36311d><li data-v-5c36311d>
      The <kbd data-v-5c36311d>genrec</kbd> combinator takes four program parameters in addition to
      whatever data parameters it needs. Fourth from the top is an if-part, followed
      by a then-part. If the if-part yields true, then the then-part is executed and
      the combinator terminates. The other two parameters are the rec1-part and the
      rec2part. If the if-part yields <code data-v-5c36311d>false</code>, the rec1-part is executed.
      Following that the four program parameters and the combinator are again pushed
      onto the stack bundled up in a quoted form. Then the rec2-part is executed, where
      it will find the bundled form. Typically it will then execute the bundled form,
      either with <code data-v-5c36311d>i</code> or with
      <code data-v-5c36311d>app2</code>, or some other combinator.
      <pre data-v-5c36311d>    g-fac == [null ] [succ] [dup pred     ] [i *   ] genrec;
      g-fib == [small] [    ] [pred dup pred] [app2 +] genrec;
  </pre><p data-v-5c36311d><li data-v-5c36311d>
      The <kbd data-v-5c36311d>linrec</kbd> combinator also takes four program parameters and is otherwise
      very similar to the <code data-v-5c36311d>genrec</code> combinator. The essential difference
      is that the bundled up quotation is immediately called before the rec2-part.
      Consequently it can only be used for <em data-v-5c36311d>linear recursion</em>. Here are programs
      for finding the
      <code data-v-5c36311d>last</code> of an aggregate or the Fibonacci value of a natural number:
      <pre data-v-5c36311d>    l-last == [rest null] [first] [rest    ] [ ] linrec;
      l-fac  == [null     ] [succ ] [dup pred] [*] linrec
  </pre><p data-v-5c36311d><li data-v-5c36311d>
      The <kbd data-v-5c36311d>binrec</kbd> combinator is again similar, but it applies the bundled
      quotation twice, once to each of the two top values which the rec1-part has left
      on the stack. It implements <em data-v-5c36311d>binary
      recursion</em>. Below it is used for the Fibonacci function and for a
      <em data-v-5c36311d>quicksort</em> program for lists (or strings).
      <pre data-v-5c36311d>  b-fib == [small] [] [pred dup pred   ] [+                 ] binrec;
  b-qsort == [small] [] [uncons [>] split] [swap23 cons concat] binrec;
  </pre><p data-v-5c36311d><li data-v-5c36311d>
      The <kbd data-v-5c36311d>tailrec</kbd> combinator is similar to the
      <code data-v-5c36311d>linrec</code> combinator, except that it does not have a rec2-part. It
      can only be used for <em data-v-5c36311d>tail recursion</em>, such as in the program below which
      returns the last element of an aggregate.
      <pre data-v-5c36311d>    t-last == [rest null] [first] [rest] tailrec;
  </pre><p data-v-5c36311d><li data-v-5c36311d>
      The <kbd data-v-5c36311d>primrec</kbd> combinator is for <em data-v-5c36311d>primitive
      recursion</em>, it has the typical if-part built in. For numeric parameters and for
      aggregate parameters it tests for
      <code data-v-5c36311d>null</code>. The rec1-part is also built in, for numeric parameters it
      returns the parameter and its predecessor, for aggregate parameters it returns
      the <code data-v-5c36311d>first</code> of the aggregate and the
      <code data-v-5c36311d>rest</code> of the aggregate. Recursion then occurs respectively on the
      predecessor or the rest, and the rudimentary rec2-part typically combines the
      results.
      <p data-v-5c36311d>
        The first program below computes the factorial (again!). The second turns any aggregate
        into a list. The third turns a suitable list of small numbers into a set. The
        fourth and fifth capitalise lists or strings of lowercase letters and produce,
        respectively, a list or string of corresponding capital letters. The last program
        takes an aggregate as parameter and produces a list of every second element
        in the original order and then the other elements in the reverse order.
      <pre data-v-5c36311d>    p-fac      ==  [1 ]  [*              ]  primrec
      agg2list   ==  [[]]  [cons           ]  primrec
      list2set   ==  [{}]  [cons           ]  primrec
      capstring  ==  [""]  [[32 -] dip cons]  primrec
      caplist    ==  [[]]  [[32 -] dip cons]  primrec
      fancy      ==  [[]]  [reverse  cons  ]  primrec
  </pre></ol><hr data-v-5c36311d></article></div></main><footer data-v-c785faa8><p data-v-c785faa8><a href="https://github.com/joy-language/joy-lang.org" data-v-c785faa8>GitHub</a></footer></div></div></div><script type="text/javascript">window.__NUXT__={layout:"default",data:[{},{}],error:null,serverRendered:!0}</script><script defer src="/_nuxt/manifest.10669f42b2e188f55eb1.js"></script><script defer src="/_nuxt/layouts/default.29c0e08e13310e3682fc.js"></script><script defer src="/_nuxt/pages/papers-on-joy.cad646018fcc11e7f563.js"></script><script defer src="/_nuxt/pages/papers-on-joy/recursion-theory-and-joy.7d268252a6e6c71fa9f2.js"></script><script defer src="/_nuxt/vendor.230cb916d1973aa790f3.js"></script><script defer src="/_nuxt/app.0a856c7cf6fb3e349fa2.js"></script>
  

